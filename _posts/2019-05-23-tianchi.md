---
layout:     post
title: 工业蒸汽量回归预测
subtitle: 阿里天池比赛持续记录
date:       2019-05-23
author:     Loopy
header-img: img/post-bg-geek.jpg
catalog: true
tags:
    - AI
    - Data

---

# 工业蒸汽量回归预测

我就不把notebook转码成md发到日志里了，代码见[GitHub仓库](https://github.com/loopyme/AliTianChi)或[天池实验室](https://tianchi.aliyun.com/home/science/scienceDetail?spm=5176.12282024.0.0.21932658B0KVpQ&userId=1095279410996#)（天池实验室中的版本可能比较新）

## 05-23
最近沉迷于刷天池，再加上要期末了，很长时间都没有更新日志了。直到今天收到了这个短信，

我才想起来是该在日志里记一记天池比赛。幸福度那个比赛稍后我整理一下。今天相当于是init一个初始的记录工业蒸汽量回归预测比赛过程的日志。

当前个人最高线上成绩是MSE=0.1301，排名在322/3011，10%左右.

这个最好成绩是两个结果直接取mean获得的。这两个结果分别是：
1. 使用未加修改的数据，15折交叉验证，用XGBoost来stack[XGBoost,LGBM,CATBoost,GradientBoost]四个模型。线上MSE是0.1368
2. 与1中相同的融合模型，但数据是全部特征训练测试集联合求rank，再分50袋的调整数据。线上  MSE也是0.1368左右（记不清了）

### 现象：
1. 暴力遍历来产生特征组合(即使检验了特定模型下的MSE Gain)对Boost系列的模型会有害
2. 特征工程的时候，无脑按value分袋有害
3. 两个MSE接近的结果直接求均值就能提高成绩(想象一个38维空间里的三角形就能解释清楚)，反而两个模型拿来stack会降低成绩
4. 尝试使用线性模型来stack，效果不好,应该是欠拟合
5. 尝试直接使用线性模型参与stack，在训练集交叉验证时结果与Boost系列模型相关度高（0.98），而在测试集下相关度明显下降（0.54）
6. 对全部特征训练测试集联合归一化，对Boost系列的模型毫无影响

### 问题：
1. stack 模型的选取
2. 针对线性模型的特征工程方式

### 思路：
1. 在原数据中增加联合rank的特征
2. 特征工程，以训练有效的线性模型